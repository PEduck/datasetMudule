{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83ffa1c8-e340-40a9-8493-ec435ffee0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xml.dom.minidom import Document\n",
    "import os\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b29db00-49f0-487c-a591-c7960008c04c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ccf771-75a1-48bb-a7c0-d3b35bc028a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93791b5a-af2b-4ba0-a5f4-e258f8d81f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'0': \"0\",  # 字典对类型进行转换\n",
    "        '1': \"1\",\n",
    "        '2': \"2\",\n",
    "        '3': \"3\",\n",
    "        '4': \"4\",\n",
    "        '5': '5',\n",
    "        '6': \"6\",\n",
    "        '7': \"7\",\n",
    "        '8': \"8\",}\n",
    "dict = {\n",
    "    '0': 'shoe',  # 鞋子\n",
    "    '1': 'bag',  # 包包\n",
    "    '2': 'upperbody',  # 上装\n",
    "    '3': 'paints',  # 裤子\n",
    "    '4': 'skirt',  # 裙子\n",
    "    '5': 'wholebody',  # 连体装\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62a160a-e492-45ba-8d84-3bf3261871dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32a7de4-6f0d-4b16-a78b-de18329cf52b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00037a54-f952-424a-8cec-953834d10dab",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2149df24-da1a-4ee8-b832-85267062862a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/home/chenyi/workspace/yolov5/datasets/\u001b[00m\n",
      "├── \u001b[01;34mcoco128\u001b[00m\n",
      "├── \u001b[01;34mdadet100kv2\u001b[00m\n",
      "├── \u001b[01;34mdadet100kv3_june\u001b[00m\n",
      "├── \u001b[01;34mdadet100kv4_1_june\u001b[00m\n",
      "├── \u001b[01;34mdadet100kv4_june\u001b[00m\n",
      "├── \u001b[01;34mdadet_gallv4_june\u001b[00m\n",
      "├── \u001b[01;34mdadetv5\u001b[00m\n",
      "├── \u001b[01;34mdadetv5_query\u001b[00m\n",
      "├── \u001b[01;34mdadetv6_1\u001b[00m\n",
      "├── \u001b[01;34mdadetv6_2\u001b[00m\n",
      "├── \u001b[01;34mdadetv6_3\u001b[00m\n",
      "├── \u001b[01;34mdataExps\u001b[00m\n",
      "├── \u001b[01;34mdeepedia\u001b[00m\n",
      "├── \u001b[01;34mdeepedia_catg6\u001b[00m\n",
      "├── \u001b[01;34mdeepedia_catg8\u001b[00m\n",
      "├── \u001b[01;34mhaowei_bag_shoe\u001b[00m\n",
      "├── \u001b[01;34mhwpedia\u001b[00m\n",
      "├── \u001b[01;34mhwpedia70k\u001b[00m\n",
      "├── \u001b[01;34mhwpedia80k\u001b[00m\n",
      "├── \u001b[01;34mtuneGallery10k\u001b[00m\n",
      "├── \u001b[01;34mtuneGallery5k\u001b[00m\n",
      "├── \u001b[01;34mtuneQuery10k\u001b[00m\n",
      "└── \u001b[01;34mvalidation_all\u001b[00m\n",
      "\n",
      "23 directories\n"
     ]
    }
   ],
   "source": [
    "!tree -d -L 1 /home/chenyi/workspace/yolov5/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3bc14db8-0d04-4930-8906-cd07f6f6d7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = 'hwpedia'\n",
    "save_root = Path(f'/home/chenyi/workspace/yolox/datasets/{folder_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cace109f-d8d1-42b6-8daa-4cdd691756ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/home/chenyi/workspace/yolov5/datasets/hwpedia\u001b[00m\n",
      "├── \u001b[01;34mimages\u001b[00m\n",
      "│   ├── \u001b[01;34mtrain\u001b[00m\n",
      "│   └── \u001b[01;34mval\u001b[00m\n",
      "└── \u001b[01;34mlabels\u001b[00m\n",
      "    ├── \u001b[01;34mtrain\u001b[00m\n",
      "    └── \u001b[01;34mval\u001b[00m\n",
      "\n",
      "6 directories\n"
     ]
    }
   ],
   "source": [
    "!tree -d -L 2 $root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "841b50c4-a2a3-42e2-884a-436def5181c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['JPEGImages', 'Annotations', 'ImageSets/Main', 'labels']\n",
    "mk_root = save_root /names[3]\n",
    "!mkdir -p $mk_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0a288726-dc1c-49b1-9200-fb994c7f4936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/home/chenyi/workspace/yolox/datasets/hwpedia/ImageSets\u001b[00m\n",
      "└── \u001b[01;34mMain\u001b[00m\n",
      "\n",
      "1 directory\n"
     ]
    }
   ],
   "source": [
    "!tree -d -L 2 $mk_root.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f9649b47-220a-4391-8616-77b15499fa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'hwpedia'\n",
    "picPath = str(save_root /names[0]) + '/'\n",
    "xmlPath = str(save_root /names[1]) + '/'\n",
    "train_val_path = str(save_root /names[2]) + '/'\n",
    "txtPath = str(save_root /names[3]) + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d5b67766-8175-4b10-b7f4-9c0b55eb144f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:00, 97.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20150720135713768.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9990it [02:45, 59.56it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20150720133904463.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29262it [09:46, 36.85it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20150720134705403.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29459it [09:50, 54.63it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "65232it [21:25, 42.87it/s] libpng warning: iCCP: known incorrect sRGB profile\n",
      "70152it [22:58, 68.34it/s] libpng warning: iCCP: known incorrect sRGB profile\n",
      "74180it [24:17, 50.88it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 16s, sys: 5min 54s, total: 17min 11s\n",
      "Wall time: 24min 18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "makexml(txtPath, xmlPath, picPath, dataset=dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d425929-d24a-4674-a501-2853f4f648e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738bbd25-68b3-4ac1-9080-989519dc062a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a728da50-bf22-4e9f-be2e-a833fa06251a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 小数据集生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e08ade4d-2da4-4fdb-beb3-88a12ab11199",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_save = Path('/nas/chenyi/datasets_nas/haowei34k_all/haowei34k_hundred')\n",
    "label_save = root_save /'labels'\n",
    "img_save = root_save /'JPEGImages'\n",
    "xml_save = root_save /'Annotations'\n",
    "\n",
    "dataset_name = 'haowei34k_hundred'\n",
    "txtPath = str(label_save) + '/'\n",
    "picPath = str(img_save) + '/'\n",
    "xmlPath = str(xml_save) + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99f82349-f16b-4504-9e50-650616c61eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_save = Path('/nas/chenyi/datasets_nas/haowei34k_all/haowei34k_hundred')\n",
    "label_save = root_save /'labels'\n",
    "img_save = root_save /'JPEGImages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c73a4fa-c9f0-4e48-8a40-84600e7fd668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a95aa7-fcb5-4acb-8bc4-c68e6ec224cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0fd24e56-ccba-483c-ab7d-d727a265e21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ...\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "pathes = glob.glob(txtPath+'*.txt')\n",
    "pathes = pathes[:100]\n",
    "# files = [Path(x).name for x in pathes]\n",
    "for i, txtsp in tqdm(enumerate(pathes)):\n",
    "    txtsp = Path(txtsp)\n",
    "    txttp = label_save /txtsp.name\n",
    "    img_sp = Path(f'{picPath}/{txtsp.stem}.jpg')\n",
    "    img_tp = img_save /img_sp.name\n",
    "    if not txttp.parent.is_dir():\n",
    "        txttp.parent.mkdir()\n",
    "    if not img_tp.parent.is_dir():\n",
    "        img_tp.parent.mkdir()\n",
    "    shutil.copyfile(txtsp, txttp)\n",
    "    shutil.copyfile(img_sp, img_tp)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c9da4e-fdc5-499d-9591-2bf30e0edf2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43cd5dc-54ca-4f49-80ed-efb54c2a22f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b57eab82-1769-41ab-ae71-622f90b75657",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### TRAIN VAL SET SPLIT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357f351c-bdd3-49bc-8b9b-5a7bc638ee14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b11f0df-0783-4597-aace-4046cf2461df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1bc62808-1ce6-4273-ad83-c6f25a6e28e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "xmlfilepath=xmlPath\n",
    "saveBasePath=train_val_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a01452-9bf0-4eb8-a564-081b1ae81a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "aec1bc58-4f99-4914-825c-eda33b7666e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_percent=0.8\n",
    "train_percent=1\n",
    "\n",
    "temp_xml = os.listdir(xmlfilepath)\n",
    "total_xml = []\n",
    "for xml in temp_xml:\n",
    "    if xml.endswith(\".xml\"):\n",
    "        total_xml.append(xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76354be-c9ad-49c4-abdc-593d603cb10b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9ca6b4d0-04fb-44e1-a339-f175d5879df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train and val size 63149\n",
      "traub suze 63149\n"
     ]
    }
   ],
   "source": [
    "num=len(total_xml)  \n",
    "list=range(num)  \n",
    "tv=int(num*trainval_percent)  \n",
    "tr=int(tv*train_percent)  \n",
    "trainval= random.sample(list,tv)  \n",
    "train=random.sample(trainval,tr)  \n",
    "\n",
    "print(\"train and val size\",tv)\n",
    "print(\"traub suze\",tr)\n",
    "ftrainval = open(os.path.join(saveBasePath,'trainval.txt'), 'w')  \n",
    "ftest = open(os.path.join(saveBasePath,'test.txt'), 'w')  \n",
    "ftrain = open(os.path.join(saveBasePath,'train.txt'), 'w')  \n",
    "fval = open(os.path.join(saveBasePath,'val.txt'), 'w')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ee8a5c-eade-4422-9daa-be7433934a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "91aa5b67-ca50-4eb0-98f8-ed64f8067c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 78937/78937 [01:16<00:00, 1038.23it/s]\n"
     ]
    }
   ],
   "source": [
    "for i  in tqdm(list):  \n",
    "    name=total_xml[i][:-4]+'\\n'  \n",
    "    if i in trainval:  \n",
    "        ftrainval.write(name)  \n",
    "        if i in train:  \n",
    "            ftrain.write(name)  \n",
    "        else:  \n",
    "            fval.write(name)  \n",
    "    else:  \n",
    "        ftest.write(name)  \n",
    "\n",
    "ftrainval.close()  \n",
    "ftrain.close()  \n",
    "fval.close()  \n",
    "ftest .close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8274f717-9f8a-4f3e-b7ca-4faf337e2e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deceff1-6a2b-4241-90c7-4f78ae087875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffe2a155-8802-4211-b862-72af63387109",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### MAKE XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bc1da8-2117-4419-b1fd-300c717911f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# makexml(txtPath, xmlPath, picPath, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080fd9e3-f7f2-4c9d-8d29-5de9a50df5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathes = glob.glob(txtPath+'*.txt')\n",
    "# pathes = pathes[:10]\n",
    "files = [Path(x).name for x in pathes]\n",
    "for i, name in tqdm(enumerate(files)):\n",
    "    xmlBuilder = Document()\n",
    "    annotation = xmlBuilder.createElement(\"annotation\")  # 创建annotation标签\n",
    "    xmlBuilder.appendChild(annotation)\n",
    "    txtFile = open(txtPath+name)\n",
    "    txtList = txtFile.readlines()\n",
    "    try:\n",
    "        img = cv2.imread(picPath+name[0:-4]+\".jpg\")\n",
    "        Pheight, Pwidth, Pdepth=img.shape\n",
    "    except:\n",
    "        img = cv2.imread(picPath+name[0:-4]+\".jpeg\")\n",
    "        Pheight, Pwidth, Pdepth=img.shape\n",
    "\n",
    "    flag = 0\n",
    "    for i in txtList:\n",
    "        flag += 1\n",
    "        oneline = i.strip().split(\" \")\n",
    "        folder = xmlBuilder.createElement(\"folder\")  # folder标签\n",
    "        folderContent = xmlBuilder.createTextNode(dataset)\n",
    "        folder.appendChild(folderContent)\n",
    "        annotation.appendChild(folder)\n",
    "        if flag == 1:\n",
    "            filename = xmlBuilder.createElement(\"filename\")  # filename标签\n",
    "            filenameContent = xmlBuilder.createTextNode(name[0:-4]+\".jpg\")\n",
    "            filename.appendChild(filenameContent)\n",
    "            annotation.appendChild(filename)\n",
    "\n",
    "            size = xmlBuilder.createElement(\"size\")  # size标签\n",
    "            width = xmlBuilder.createElement(\"width\")  # size子标签width\n",
    "            widthContent = xmlBuilder.createTextNode(str(Pwidth))\n",
    "            width.appendChild(widthContent)\n",
    "            size.appendChild(width)\n",
    "            height = xmlBuilder.createElement(\"height\")  # size子标签height\n",
    "            heightContent = xmlBuilder.createTextNode(str(Pheight))\n",
    "            height.appendChild(heightContent)\n",
    "            size.appendChild(height)\n",
    "            depth = xmlBuilder.createElement(\"depth\")  # size子标签depth\n",
    "            depthContent = xmlBuilder.createTextNode(str(Pdepth))\n",
    "            depth.appendChild(depthContent)\n",
    "            size.appendChild(depth)\n",
    "            annotation.appendChild(size)\n",
    "\n",
    "        object = xmlBuilder.createElement(\"object\")\n",
    "        picname = xmlBuilder.createElement(\"name\")\n",
    "        nameContent = xmlBuilder.createTextNode(dict[oneline[0]])\n",
    "        picname.appendChild(nameContent)\n",
    "        object.appendChild(picname)\n",
    "        pose = xmlBuilder.createElement(\"pose\")\n",
    "        poseContent = xmlBuilder.createTextNode(\"Unspecified\")\n",
    "        pose.appendChild(poseContent)\n",
    "        object.appendChild(pose)\n",
    "        truncated = xmlBuilder.createElement(\"truncated\")\n",
    "        truncatedContent = xmlBuilder.createTextNode(\"0\")\n",
    "        truncated.appendChild(truncatedContent)\n",
    "        object.appendChild(truncated)\n",
    "        difficult = xmlBuilder.createElement(\"difficult\")\n",
    "        difficultContent = xmlBuilder.createTextNode(\"0\")\n",
    "        difficult.appendChild(difficultContent)\n",
    "        object.appendChild(difficult)\n",
    "        bndbox = xmlBuilder.createElement(\"bndbox\")\n",
    "        xmin = xmlBuilder.createElement(\"xmin\")\n",
    "        mathData=int(((float(oneline[1]))*Pwidth+1)-(float(oneline[3]))*0.5*Pwidth)\n",
    "        xminContent = xmlBuilder.createTextNode(str(mathData))\n",
    "        xmin.appendChild(xminContent)\n",
    "        bndbox.appendChild(xmin)\n",
    "        ymin = xmlBuilder.createElement(\"ymin\")\n",
    "        mathData = int(((float(oneline[2]))*Pheight+1)-(float(oneline[4]))*0.5*Pheight)\n",
    "        yminContent = xmlBuilder.createTextNode(str(mathData))\n",
    "        ymin.appendChild(yminContent)\n",
    "        bndbox.appendChild(ymin)\n",
    "        xmax = xmlBuilder.createElement(\"xmax\")\n",
    "        mathData = int(((float(oneline[1]))*Pwidth+1)+(float(oneline[3]))*0.5*Pwidth)\n",
    "        xmaxContent = xmlBuilder.createTextNode(str(mathData))\n",
    "        xmax.appendChild(xmaxContent)\n",
    "        bndbox.appendChild(xmax)\n",
    "        ymax = xmlBuilder.createElement(\"ymax\")\n",
    "        mathData = int(((float(oneline[2]))*Pheight+1)+(float(oneline[4]))*0.5*Pheight)\n",
    "        ymaxContent = xmlBuilder.createTextNode(str(mathData))\n",
    "        ymax.appendChild(ymaxContent)\n",
    "        bndbox.appendChild(ymax)\n",
    "        object.appendChild(bndbox)\n",
    "\n",
    "        annotation.appendChild(object)\n",
    "\n",
    "    f = open(xmlPath+name[0:-4]+\".xml\", 'w')\n",
    "    xmlBuilder.writexml(f, indent='\\t', newl='\\n', addindent='\\t', encoding='utf-8')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fb1aa0-5286-4c2a-beaf-48ac50bf4ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cc4ae0-3d6e-424f-a4b6-7bc10b66ab09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "42fd2fa0-201d-4c28-ae41-47ef9c359aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makexml(txtPath, xmlPath, picPath, dataset='VOC2007'):  # 读取txt路径，xml保存路径，数据集图片所在路径\n",
    "#     files = os.listdir(txtPath)\n",
    "    pathes = glob.glob(txtPath+'*.txt')\n",
    "    pathes = pathes[4760:]\n",
    "    files = [Path(x).name for x in pathes]\n",
    "    for i, name in tqdm(enumerate(files)):\n",
    "        xmlBuilder = Document()\n",
    "        annotation = xmlBuilder.createElement(\"annotation\")  # 创建annotation标签\n",
    "        xmlBuilder.appendChild(annotation)\n",
    "        txtFile = open(txtPath+name)\n",
    "        txtList = txtFile.readlines()\n",
    "        try:\n",
    "            img = cv2.imread(picPath+name[0:-4]+\".jpg\")\n",
    "            Pheight, Pwidth, Pdepth=img.shape\n",
    "        except:\n",
    "            print(name)\n",
    "            continue\n",
    "\n",
    "        flag = 0\n",
    "        for i in txtList:\n",
    "            flag += 1\n",
    "            oneline = i.strip().split(\" \")\n",
    "            folder = xmlBuilder.createElement(\"folder\")  # folder标签\n",
    "            folderContent = xmlBuilder.createTextNode(dataset)\n",
    "            folder.appendChild(folderContent)\n",
    "            annotation.appendChild(folder)\n",
    "            if flag == 1:\n",
    "                filename = xmlBuilder.createElement(\"filename\")  # filename标签\n",
    "                filenameContent = xmlBuilder.createTextNode(name[0:-4]+\".jpg\")\n",
    "                filename.appendChild(filenameContent)\n",
    "                annotation.appendChild(filename)\n",
    "\n",
    "                size = xmlBuilder.createElement(\"size\")  # size标签\n",
    "                width = xmlBuilder.createElement(\"width\")  # size子标签width\n",
    "                widthContent = xmlBuilder.createTextNode(str(Pwidth))\n",
    "                width.appendChild(widthContent)\n",
    "                size.appendChild(width)\n",
    "                height = xmlBuilder.createElement(\"height\")  # size子标签height\n",
    "                heightContent = xmlBuilder.createTextNode(str(Pheight))\n",
    "                height.appendChild(heightContent)\n",
    "                size.appendChild(height)\n",
    "                depth = xmlBuilder.createElement(\"depth\")  # size子标签depth\n",
    "                depthContent = xmlBuilder.createTextNode(str(Pdepth))\n",
    "                depth.appendChild(depthContent)\n",
    "                size.appendChild(depth)\n",
    "                annotation.appendChild(size)\n",
    "\n",
    "            object = xmlBuilder.createElement(\"object\")\n",
    "            picname = xmlBuilder.createElement(\"name\")\n",
    "            nameContent = xmlBuilder.createTextNode(dict[oneline[0]])\n",
    "            picname.appendChild(nameContent)\n",
    "            object.appendChild(picname)\n",
    "            pose = xmlBuilder.createElement(\"pose\")\n",
    "            poseContent = xmlBuilder.createTextNode(\"Unspecified\")\n",
    "            pose.appendChild(poseContent)\n",
    "            object.appendChild(pose)\n",
    "            truncated = xmlBuilder.createElement(\"truncated\")\n",
    "            truncatedContent = xmlBuilder.createTextNode(\"0\")\n",
    "            truncated.appendChild(truncatedContent)\n",
    "            object.appendChild(truncated)\n",
    "            difficult = xmlBuilder.createElement(\"difficult\")\n",
    "            difficultContent = xmlBuilder.createTextNode(\"0\")\n",
    "            difficult.appendChild(difficultContent)\n",
    "            object.appendChild(difficult)\n",
    "            bndbox = xmlBuilder.createElement(\"bndbox\")\n",
    "            xmin = xmlBuilder.createElement(\"xmin\")\n",
    "            mathData=int(((float(oneline[1]))*Pwidth+1)-(float(oneline[3]))*0.5*Pwidth)\n",
    "            xminContent = xmlBuilder.createTextNode(str(mathData))\n",
    "            xmin.appendChild(xminContent)\n",
    "            bndbox.appendChild(xmin)\n",
    "            ymin = xmlBuilder.createElement(\"ymin\")\n",
    "            mathData = int(((float(oneline[2]))*Pheight+1)-(float(oneline[4]))*0.5*Pheight)\n",
    "            yminContent = xmlBuilder.createTextNode(str(mathData))\n",
    "            ymin.appendChild(yminContent)\n",
    "            bndbox.appendChild(ymin)\n",
    "            xmax = xmlBuilder.createElement(\"xmax\")\n",
    "            mathData = int(((float(oneline[1]))*Pwidth+1)+(float(oneline[3]))*0.5*Pwidth)\n",
    "            xmaxContent = xmlBuilder.createTextNode(str(mathData))\n",
    "            xmax.appendChild(xmaxContent)\n",
    "            bndbox.appendChild(xmax)\n",
    "            ymax = xmlBuilder.createElement(\"ymax\")\n",
    "            mathData = int(((float(oneline[2]))*Pheight+1)+(float(oneline[4]))*0.5*Pheight)\n",
    "            ymaxContent = xmlBuilder.createTextNode(str(mathData))\n",
    "            ymax.appendChild(ymaxContent)\n",
    "            bndbox.appendChild(ymax)\n",
    "            object.appendChild(bndbox)\n",
    "\n",
    "            annotation.appendChild(object)\n",
    "\n",
    "        f = open(xmlPath+name[0:-4]+\".xml\", 'w')\n",
    "        xmlBuilder.writexml(f, indent='\\t', newl='\\n', addindent='\\t', encoding='utf-8')\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31885426-e142-455c-8b93-db421d51478a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71449846-8bb2-4fe6-acc7-8301df09f651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a3e1ee-289b-436e-8ed5-ed4ec735c799",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
